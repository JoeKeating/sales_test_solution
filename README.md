{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42fcbd51-78bf-4bf3-82e6-c48a0b134c61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Morris & Dickson Sales Pipeline\n",
    "\n",
    "## 1. Project Overview\n",
    "This repository contains a take-home exercise completed as part of the interview process with **Morris & Dickson**. The assignment was to build a simple, end-to-end data pipeline from provided JSON sales data into a medallion architecture and to produce a small set of business-facing dashboards.\n",
    "\n",
    "At the hiring manager’s suggestion, the solution was implemented using **Databricks Free Edition** to demonstrate familiarity with tools used by the team, while keeping the overall scope intentionally modest. \n",
    "\n",
    "---\n",
    "\n",
    "## 2. Stakeholder Questions\n",
    "The stakeholder requirements for this exercise were intentionally focused:\n",
    "\n",
    "- View **sales by customer**\n",
    "- View **sales by geographic location**\n",
    "\n",
    "The pipeline and downstream analytics are designed specifically to support these questions without unnecessary complexity.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Dataset\n",
    "The dataset  consists of JSON files representing a small sales domain. At a high level, the data includes:\n",
    "\n",
    "- Customers  \n",
    "- Products  \n",
    "- Orders  \n",
    "- Sales transactions  \n",
    "- Country / geographic reference data  \n",
    "\n",
    "---\n",
    "\n",
    "## 4. Architecture Overview\n",
    "The solution follows a  **medallion architecture** pattern:\n",
    "\n",
    "- **Bronze**: Raw ingestion of source JSON files with minimal transformation  \n",
    "- **Silver**: Cleaned, normalized tables suitable for relational joins and modeling  \n",
    "- **Gold**: Analytics-ready tables designed for consumption by BI tools  \n",
    "\n",
    "---\n",
    "\n",
    "## 5. Technology Choices\n",
    "Tech stack for this project:\n",
    "\n",
    "- **Databricks Free Edition** – execution environment (used per hiring manager guidance)  \n",
    "- **PySpark** – data ingestion and transformation  \n",
    "- **Python** – supporting logic and notebook organization  \n",
    "- **CSV exports** – used to bridge Databricks outputs into Power BI  \n",
    "- **Power BI** – dashboarding and visualization  \n",
    "\n",
    "While orchestration tools were not required for this exercise, the structure reflects patterns that would translate cleanly to scheduled or orchestrated pipelines.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Repository Structure\n",
    "The repository is organized to mirror the logical flow of the pipeline:\n",
    "\n",
    "- `notebooks/` – Databricks notebooks for ingestion, transformation, and modeling  \n",
    "- `data/` – Exported CSV files produced from the Gold layer for BI consumption  \n",
    "- `powerbi/` – Power BI report file(s)  \n",
    "- `README.md` – Project overview and documentation  \n",
    "\n",
    "---\n",
    "\n",
    "## 7. Data Pipeline Walkthrough\n",
    "\n",
    "### 7.1 Bronze Layer\n",
    "The Bronze layer ingests the raw JSON files exactly as provided. Minimal changes are applied beyond basic parsing and column normalization where required to load the data reliably.\n",
    "\n",
    "\n",
    "### 7.2 Silver Layer\n",
    "In the Silver layer, raw data is cleaned and normalized:\n",
    "\n",
    "- Column names are standardized  \n",
    "- Data types are corrected  \n",
    "- Reference data (e.g., countries) is resolved  \n",
    "- Relationships between entities are made explicit  \n",
    "\n",
    "These tables are designed to be reusable building blocks for downstream analytics.\n",
    "\n",
    "### 7.3 Gold Layer\n",
    "The Gold layer reshapes Silver tables into analytics-ready structures. Fact and dimension tables are created with a clear grain, making them easy to consume in Power BI without additional transformation logic.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Analytics Layer (Gold)\n",
    "The Gold layer supports reporting through:\n",
    "\n",
    "- A sales fact table containing transactional measures  \n",
    "- Dimension tables for customers, products, dates, and geography  \n",
    "\n",
    "---\n",
    "\n",
    "## 9. Dashboard Overview\n",
    "The Power BI dashboard built on top of the Gold layer includes:\n",
    "\n",
    "- Sales by customer  \n",
    "- Sales by geographic location  \n",
    "- Basic filtering and aggregation to support exploratory analysis  \n",
    "\n",
    "The dashboard is intentionally simple and focused on answering the stated stakeholder questions.\n",
    "\n",
    "---\n",
    "\n",
    "## 10. How to Reproduce\n",
    "A full local reproduction is not required to review the solution. To explore the project:\n",
    "\n",
    "1. Clone the repository  \n",
    "2. Review the Databricks notebooks for each pipeline stage  \n",
    "3. Inspect the exported Gold-layer CSV files  \n",
    "4. Open the Power BI report to view the dashboards\n",
    "\n",
    "Notebooks were executed sequentially.\n",
    "\n",
    "---\n",
    "\n",
    "## 11. Notes & Assumptions\n",
    "- The dataset is static and provided solely for this exercise  \n",
    "- Pipelines are executed manually  \n",
    "- The solution prioritizes clarity and correctness over scalability or automation  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "README.md",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
